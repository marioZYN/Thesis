#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\options openright
\use_default_options false
\master ../thesis.lyx
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding T1
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 1
\use_package mhchem 0
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\use_minted 0
\index Indice
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style swiss
\dynamic_quotes 0
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Inception Network
\end_layout

\begin_layout Standard
The Inception network is an important milestone of CNN classifiers.
 Before Inception network, most popular CNN networks just stack convolution
 layers deeper and deeper, hoping to get better performance.
 However, deeper network has more parameters which make gradient descent
 less effective and lead to overfitting.
 The Inception network is carefully designed in terms of speed and accuracy
 while keeping the computational budget constant.
 The network is organized in the form of 
\begin_inset Quotes cld
\end_inset

Inception module
\begin_inset Quotes crd
\end_inset

 which makes it possible for the network to grow both in width and depth.
 The performance is verified by GoogleLeNet, a 22 layers deep network which
 won ILSVRC14 competition.
 
\end_layout

\begin_layout Standard
The main difference between Inception module and normal CNN convolution
 layer is that Inception uses various sizes of filters in each layer while
 CNN uses only one.
 The idea of Inception architecture is based on finding out how an optimal
 local sparse structure in a convolutional vision network can be approximated.
 One straight forward way is to use more than one filter size and let the
 training phase to decide the best approximation area.
 The outputs of each filter are stacked together to form the input of the
 next stage.
 As we can see in the figure, there are three shapes of filter: 1x1, 3x3
 and 5x5.
 The 1x1 filter is also used for dimension reduction.
 In the left figure, we can see the naive implementation of this idea.
 This implementation, however, has one big issue, even a modest number of
 5x5 convolutions can be prohibitively expensive on top of a convolutional
 layer with a large number of filters.
 This problem becomes even more pronounced when we stack all the outputs
 together.
 This leads to the second implementation structure, as we can see in the
 right figure.
 Whenever the computational requirements increase too much, we can simply
 apply a 1x1 convolution to reduce the dimension.
 Another thing to mention is the max pooling layer, it exists for no particular
 reason.
 Historically, good performance networks have pooling layers.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/inception_model_native.png
	lyxscale 10
	width 50text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Inception module, naive version
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/inception_model_real.png
	lyxscale 10
	width 50text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Inception module with dimension reductions
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Inception-module"

\end_inset

Inception module
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Inception module is the fundamental element in inception architectures.
 By concatenating various sizes of filters in each layer and using 1x1 filters
 to reduce dimensions, the network can grow wider and deeper.
 Since Inception module is invented, several improvements are made over
 the years.
 However in this thesis, we only use the idea of stacking various sizes
 of filters and ignore other tricks.
 So the details of the improvements are not discussed here, only a summary
 is provided.
 
\end_layout

\begin_layout Itemize
Inception v1 concatenates Inception modules to make the network wider and
 deeper
\end_layout

\begin_layout Itemize
Inception v2 uses two 3x3 filters to replace 5x5 filters, decomposes nxn
 filers into 1xn and nx1 filters in order to increase computation speed
\end_layout

\begin_layout Itemize
Inception v3 introduces rmsprop, factorized 7x7 filters and batch normalization
\end_layout

\begin_layout Itemize
Inception v4 uses the idea of ResNet
\end_layout

\begin_layout Section
Count-Ception Architecture
\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
